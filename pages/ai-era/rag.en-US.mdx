import { Steps } from 'nextra/components'

# ðŸ”— RAG (Retrieval-Augmented Generation) Practice Sharing

## What is RAG?

Imagine if you were to write a report on "Mars exploration" but weren't familiar with the topic. You might start by searching for information online and then write your report based on what you find. Retrieval-Augmented Generation (RAG) is a process similar to this, but performed by a machine.

Simply put, RAG involves two steps:

1. **Finding Information**: Just like you search online for information about "Mars exploration," RAG first looks for information related to the posed question in a vast knowledge base. This step ensures it has enough material to answer the question.

2. **Writing the Answer**: With this information, RAG then uses a special program (called a generation model) to "write" an answer or generate relevant text. This program attempts to express the found information in a coherent and reasonable way.

In short, RAG is an automated process that helps machines "learn" how to better answer questions or generate text by looking up information. This means the content generated by machines is not just made up but based on solid information, making it generally more accurate and rich.

## Why do we need RAG?

Retrieval-Augmented Generation (RAG) is important because it effectively addresses various issues encountered when using large language models, significantly improving the quality and accuracy of generated content:

1. **Making generated content more timely**: The timeliness of a large language model's data depends on its training data, which is not updated after training is completed. This often makes the information held by the language model outdated. By incorporating RAG into the process, the model can access the latest information and generate content that reflects the current state of knowledge. This is particularly important for applications that require up-to-date data support.

2. **Handling knowledge-intensive tasks**: In most scenarios, the knowledge and data already held by large language models are insufficient to handle tasks that require extensive background knowledge, such as writing detailed reports on specific topics. RAG can enrich its answers by quickly integrating and retrieving relevant information from different knowledge bases, making the generated content more accurate and informative.

3. **Improving the relevance and quality of generated text**: Generation models (like the GPT series) may produce answers that are irrelevant or partially incorrect (hallucinations) without direct access to specific data. RAG can ensure the quality and relevance of the output by first retrieving relevant information and then generating text based on this information.

4. **Mitigating data scarcity issues**: For certain domains or niche topics, there may not be enough training data to train an efficient generation model. RAG addresses this by utilizing external knowledge bases, providing high-quality output even in situations of data scarcity.

Overall, RAG offers an effective way to tackle complex tasks by combining retrieval and generation methods, enhancing the machine's understanding and text generation capabilities, making the generated content not only more accurate but also richer and more diverse.

## RAG Practice

The RAG (Retrieval-Augmented Generation) pipeline can be divided into four stages:

1. **Question Rewriting (Rewriter)**: Diverges and answers the user's input question to obtain more keywords relevant to the original question.
2. **Keyword Retrieval (Retriever)**: Uses vector matching, keyword matching, search engines, etc., based on the question-answer pairs provided by the Rewriter, to recall content from the database.
3. **Data Reranking (Reranker)**: Finds the n most relevant pieces of data from the textual content provided by the Retriever, based on the user's original input question.
4. **Summarizing Answer (Reader)**: Understands the user's original input question, reads the n most relevant pieces of data found, summarizes, and provides an answer, including the sources of the information.

Next, I will share a practical case study to illustrate how the entire RAG pipeline works:

<Steps>

### Rewriter

- **Objective**: To diverge and answer the user's input question to obtain more keywords relevant to the original question.
- **Dependent capabilities**: Prompt engineering + large models.
- **Input**: The user's original question.
- **Output**: Multiple question-answer pairs rewritten based on the original question.

#### Example

- Suppose the user's original input question is: "What are some fun places around Hangzhou?"
- After question rewriting, the following question-answer pairs are generated:
  ```
    1. What are the historical and cultural attractions around Hangzhou? The area around Hangzhou has rich historical and cultural resources. West Lake is one of the most famous attractions, listed as a World Cultural Heritage site for its "landscape gardens." Songcheng is a must-visit historical and cultural experience site, a large theme park based on historical culture. Lingyin Temple, a well-known ancient Buddhist temple, is famous worldwide.
    2. What are some places around Hangzhou suitable for family trips? There are many places around Hangzhou suitable for family trips. For example, Hangzhou Wildlife World is a large zoo where families can get close to and learn about various animals. Hangzhou Paradise and Songcheng's Song Dynasty Town are also good choices for family trips, offering a variety of entertainment facilities and performances.
    3. What are the natural scenic areas around Hangzhou? There are various natural scenic spots around Hangzhou, among which Huangshan is one of the most well-known, famous for its unique pine trees, peculiar rocks, sea of clouds, and hot springs. Tianmu Mountain is also worth visiting for its rich biodiversity and fresh air. Additionally, Thousand Island Lake is a popular tourist destination known for its clear water quality and numerous islands.
  ```
- Thus, in the next step, when the Retriever recalls relevant content, the keywords can be expanded from the original: `Hangzhou`, `surrounding`, `fun places` to `Hangzhou`, `surrounding`, `historical cultural attractions`, `West Lake`, `landscape gardens`, `Songcheng`, `historical cultural theme park`, etc., significantly increasing the volume of content that can be recalled.

### Retriever

- **Objective**: To recall content from the database using vector matching, keyword matching, search engines, etc., based on question-answer pairs provided by the Rewriter.
- **Dependent capabilities**: Vector search, data graphs, search engines.
- **Input**: Question-answer pairs provided by the Rewriter.
- **Output**: Top 50 text contents recalled for each question-answer pair.

#### Example

Based on the question-answer pairs provided by the Rewriter in step 1 and the included keywords (`Hangzhou`, `surrounding`, `historical cultural attractions`, `West Lake`, `landscape gardens`, `Songcheng`, etc.), recall 50 relevant contents from the database for each question-answer pair.

### Reranker

- **Objective**: To find the n most relevant pieces of data from the text content provided by the Retriever, based on the user's original input question.
- **Dependent capabilities**: bg_rank small model.
- **Input**: The user's original question, text content provided by the Retriever.
- **Output**: The n most relevant text contents.

#### Example

Based on the user's original question "What are some fun places around Hangzhou?" find the Top n from a large amount of text content provided by the Retriever in step 2.

### Reader

- **Objective**: To understand the user's original input question, read the n most relevant data output by the Reranker, summarize, and provide an answer, citing the sources.
- **Dependent capabilities**: Prompt engineering + large models.
- **Input**: The user's original question, the n most relevant data output by the Reranker.
- **Output**: An answer with sources.

#### Example

Based on the user's original question "What are some fun places around Hangzhou?" and the n most relevant data (including their links) provided by the Reranker in step 3, produce the answer output:
```
There are many places worth exploring around Hangzhou, suitable for different types of visitors:

1. West Lake: As the symbol of Hangzhou, West Lake is not only a must-visit attraction in Hangzhou but also the starting point for surrounding tours. You can take a boat ride on the lake, stroll along the Su Causeway in spring, or experience the poetic beauty of Broken Bridge in winter.
2. Lingyin Temple: Located under the Flying Peak in Hangzhou's West Lake area, it is a historic Buddhist temple known for its serene mountain and forest scenery and its simple and solemn temple complex, suitable for visitors seeking peace of mind.
3. Songcheng:

Located in the West Lake District of Hangzhou, it is a large theme park that integrates Song Dynasty culture, history, entertainment, and performances. The "Songcheng Eternal Love" show is especially recommended for a stunning audio-visual feast.

Sources: [1], [2], [3]
```

</Steps>

## Summary

Retrieval-Augmented Generation (RAG) is a content generation scheme that combines retrieval and generation capabilities.

Starting from a user's question, it diverges into several related question-answer pairs (including answers in the divergence helps generate different keywords), retrieves relevant information from a large knowledge base using the keywords included in the question-answer pairs, and after filtering and ranking, generates answers or text based on this information, thereby improving the quality and relevance of the model's output.

The RAG method combines the efficiency of retrieval systems with the flexibility of generation models, providing more accurate and rich outputs when handling complex queries or tasks.